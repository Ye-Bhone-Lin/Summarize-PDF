{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'D:\\\\Programming\\\\Summarize PDF\\\\IRT_Machine_Translation.pdf', 'page': 0}, page_content='See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/320730405\\nMachine Translation\\nPreprint · October 2017\\nCITATIONS\\n0\\nREADS\\n38,236\\n1 author:\\nMuhammad Irfan\\nBahria University\\n1 PUBLICATION\\xa0\\xa0\\xa00 CITATIONS\\xa0\\xa0\\xa0\\nSEE PROFILE\\nAll content following this page was uploaded by Muhammad Irfan on 31 October 2017.\\nThe user has requested enhancement of the downloaded file.'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize PDF\\\\IRT_Machine_Translation.pdf', 'page': 1}, page_content='Machine Translation\\nMuhammad Irfan\\nDepartment of Computer Science\\nBahria University Islamabad\\nEmail: muhammad.Irfan@outlook.com\\nAbstract—Language is core medium of communication and\\ntranslation is core tool for the understand the information\\nin unknown language.Machine translation helps the people to\\nunderstand the information of unknown language without the\\nhelp of Human translator. This study is brief introduction to\\nmachine translation.\\nKeywords— Machine Translation, Rule-base Machine Transla-\\ntion, Example-base Machine Translation, Statistical Machine.\\nI. L ITERATURE REVIEW\\nThe idea of universal language was found in 17th century\\n[3].The concept of translation was base on word-to-word\\ntranslation.\\nWith modern computer and advance computation linguistics\\nman has able to develop automatic machine translation. The\\nEra of modern machine translation started in 1940s and\\nupto 1960 much work was done in advance linguistics[3]. In\\n1966 the Automatic Language Processing Advisory Committee\\n(ALPAC) reported that Machine Translation could not produce\\nquality translations as human translators[3], [2].\\nIn 1980s IBM started work in statistical machine translation\\nand 1990s the parallel text availability had increased the\\ninterest in statistical machine translation. In 2006 an open-\\nsource Statistical Machine Translation tool called Moses was\\nreleased and it currently the most complete Statistical Machine\\nTranslation software available[1].\\nIn 2008 a text/SMS translation service for mobiles was intro-\\nduced in Japan. In 2009 speech-to-speech translation were pro-\\nvided in mobile phone for English, Japanese and Chinese.The\\nNeural machine translation is a new approach to machine\\ntranslation proposed by Kalchbrenner and Blunsom in 2013[4].\\nII. I NTRODUCTION\\nLanguage is medium in which human can express his/her\\nidea. The total estimated language in world are between three\\nthousand to eight thousand. It is very difﬁcult to understand\\nevery language but the languages are the only medium of\\ncommunication in human society. The idea of translation\\nintroduces to communicate messages from one language to\\nothers.\\nMachine Translation (MT)\\nMachine Translation means automatic translation, It the\\nﬁeld of Artiﬁcial Intelligence. Machine translation is computer\\nprogram which is design to translate text from one language\\n(source language) to another language (target language) with-\\nout the help of human. The aim of Machine Translation is to\\nprovide a system that translate text of source language into\\ntarget language and translation express the same meaning as\\nit in source language.\\nGeneral Translation step\\nAny human translation can be described in following steps\\n• Decode the Source Text\\n• Re-encode it into Target language\\nBoth decoding and encode require deep knowledge of source\\nlanguage(SL) and target language (TL). This includes gram-\\nmar, semantic syntax understanding of both languages. Natural\\nLanguage are very complex in term words meaning, grammar\\nrules etc.\\nMachine Translation Approaches\\nThe machine translation approaches are rule-based approach\\nand corpus-based approach. For rule base machine translation,\\nHuman expert deﬁne set of rules for the translation process\\nwhile in corpus base approach rules are automatically ex-\\ntracted.\\n1) Rule-based Machine Translation(RBMT) Approach:The\\nRule-based Machine Translation works on the morphology,\\nsyntax and semantic of both languages. So, we required\\nthe syntax analysis, semantic analysis of Source text and to\\ngenerate the text in target language we need syntax generation\\nand semantic generation. We also need the bilingual dictionary\\nof source and target languages. General Steps of Rule-based\\nMachine Translation are described in ﬁgure 1.\\nFig. 1. Rule-based Machine Translation\\nSub approaches in RBMT\\nThe sub approaches in rule-based Machine translation\\nare direct, transfer-based, interlingual Machine Translation\\napproaches.'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize PDF\\\\IRT_Machine_Translation.pdf', 'page': 2}, page_content='Direct Machine Translation Approach:\\nThis is oldest approach and translation is performed at word\\nlevel. There is no additional intermediary representation be-\\ntween source and target languages. Words of source language\\ntext is directly translated into the target language. This is\\nuni-directional bilingual translation system. Direct machine\\ntranslation approach involves the word by word translation\\nwith some modiﬁcation at grammar level. The translation is\\nnot good as it is just the replacement of words from target\\nlanguage into source language text i-e word by word meaning\\nreplacement.\\nInterlingual Machine Translation Approach:\\nThis approach introduces an intermediary language represen-\\ntation between source and target languages. This intermediary\\nlanguage is called Neutral Language. Neutral language can\\nrepresent any natural language. It is independent of source and\\ntarget Languages. It is also useful for multilingual translation\\nmachine system.KANT system was developed on interlingual\\napproach in 1992 by Nyberg and Mitamura[5]. Building in-\\nterlingual language is not an easy job. Too much efforts are\\nrequired to develop truly neutral language.\\nTransfer base Machine Translation Approach\\nIn this approach the text of source language is converted\\ninto intermediary representation, it is then used to generate\\nthe target language text with help bilingual dictionary and\\ngrammar rules. Transfer based machine translation process is\\ndivided into three phases.\\nAnalysis\\nIn this phase source language text is analyzed on basis of lin-\\nguistic information and heuristics to parser the text (syntactic\\nrepresentation)\\nTransfer\\nThe syntactic representation of source language is converted\\ninto the syntactic form of target language.\\nGeneration\\nThe ﬁnal text in target language is generate with help of\\nmorphological analysis. This approach heavily dependent on\\nthe grammar and structure of sentence and changes to a\\nmonolingual component affect all transfer modules for that\\nlanguage.\\n2) Corpus-based Machine Translation Approach:It is ac-\\ntually data driven machine translation. It was introduced an\\nalternative approach to the rule-based approach. In this ap-\\nproach the bilanguage parallel corpus is used to extract the\\ntranslation for new sentences. A large amount of raw data\\nis collected in parallel corpora. The raw data is actually the\\ntranslation between source and target languages and this data\\nis used for translation. The sub-approaches of Corpus-based\\nMachine Translation are Statistical Machine Translation and\\nExample-based Machine Translation.\\nStatistical Machine Translation(SMT)\\nThis approach is basis on statistical model. It has two statistical\\nprobabilities models: language model and translation model\\nand massive parallel corpora of source and target languages.\\nThe advantage of SMT system is that linguistic knowledge\\nis not required for building them. The difﬁculty in SMT\\nsystem is creating massive parallel corpus. We have to two\\nmodels in SMT, one is Word-based and other is phrase-based.\\nIn word-bases MT sentences are consider as combination of\\nsingle words and structure relation between the words are\\nignored while in phrase-based model consider sentences as\\ncombination of phrases or chunk. The basic concept in SMT\\nis probability. The probability score of translations are gen-\\nerated from already available translated data (parallel corpus,\\ntranslated by human), the translation having high probability is\\nselected as ﬁnal translation. The probability is calculated with\\nhelp of language and translation models.\\nA huge amount of data is need for SMT and evolved many\\ntraining repetition process. There is also no speciﬁc method\\nquality control of corpora.\\nFig. 2. Statistical Machine Translation\\nExample-based Machine Translation (EBMT)\\nExample-based machine translation contains the point to point\\nmapping between the source and target language sentences i-e\\nwe have examples data that is translated between the source\\nand target language[6]. This data is used for translation. The\\nbasic idea is if already translated sentence occur again it, the\\nsame translation is likely to be correct again. Basically, EBMT\\nis memory-based translation and the concept of analogy is used\\nfor the translation.\\nFig. 3. Example-based Machine Translation\\nIII. C ONCLUSION\\nMany approaches have been proposed but none of them\\nproduce equivalent translation between target and source lan-\\nguages. It is difﬁcult to achieve 100 percent accuracy in trans-\\nlation due the complexity nature of natural Languages. Every\\nnatural language having different sentence structures, grammar\\nand lexicons. However, combining the best feature of different\\napproaches into hybrid approach can improve the accuracy of\\ntranslation. This quality improvement can increase the machine\\ntranslation role in cross-language Information Retrieval System\\nand Multilingual Information Retrieval systems.\\nACKNOWLEDGMENT\\nThe author would like to thank Dr. Arif UR Rehman Bahria\\nUniversity Islamabad.'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize PDF\\\\IRT_Machine_Translation.pdf', 'page': 3}, page_content='REFERENCES\\n[1] Statistical Machine Translation. http://www.statmt.org/.\\n[2] Translation Automation Timeline. https://www.taus.net/academy/timelines/translation-\\nautomation-timeline.\\n[3] John Hutchins. Machine translation: History and general principles. The\\nencyclopedia of languages and linguistics, 5:2322–2332, 1994.\\n[4] Nal Kalchbrenner and Phil Blunsom. Recurrent continuous translation\\nmodels. In EMNLP, volume 3, page 413, 2013.\\n[5] Eric H. Nyberg and Teruko Mitamura. The kant system: Fast, accurate,\\nhigh-quality translation in practical domains. In Proceedings of the\\n14th Conference on Computational Linguistics - Volume 3, COLING\\n’92, pages 1069–1073, Stroudsburg, PA, USA, 1992. Association for\\nComputational Linguistics.\\n[6] MD Okpor. Machine translation approaches: issues and challenges.\\nInternational Journal of Computer Science Issues (IJCSI), 11(5):159,\\n2014.\\nView publication stats')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_loader = PyPDFLoader(r\"D:\\Programming\\Summarize PDF\\IRT_Machine_Translation.pdf\")\n",
    "pages = pdf_loader.load()\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "chunk = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap = False)\n",
    "split_pdf = chunk.split_documents(pages)\n",
    "print(len(split_pdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_12620\\1104683074.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  db = FAISS.from_documents(documents=split_pdf, embedding=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "db = FAISS.from_documents(documents=split_pdf, embedding=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"))\n",
    "db.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
