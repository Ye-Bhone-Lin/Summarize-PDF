{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\IRT_Machine_Translation.pdf', 'page': 0}, page_content='See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/320730405\\nMachine Translation\\nPreprint · October 2017\\nCITATIONS\\n0\\nREADS\\n38,236\\n1 author:\\nMuhammad Irfan\\nBahria University\\n1 PUBLICATION\\xa0\\xa0\\xa00 CITATIONS\\xa0\\xa0\\xa0\\nSEE PROFILE\\nAll content following this page was uploaded by Muhammad Irfan on 31 October 2017.\\nThe user has requested enhancement of the downloaded file.'), Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\IRT_Machine_Translation.pdf', 'page': 1}, page_content='Machine Translation\\nMuhammad Irfan\\nDepartment of Computer Science\\nBahria University Islamabad\\nEmail: muhammad.Irfan@outlook.com\\nAbstract—Language is core medium of communication and\\ntranslation is core tool for the understand the information\\nin unknown language.Machine translation helps the people to\\nunderstand the information of unknown language without the\\nhelp of Human translator. This study is brief introduction to\\nmachine translation.\\nKeywords— Machine Translation, Rule-base Machine Transla-\\ntion, Example-base Machine Translation, Statistical Machine.\\nI. L ITERATURE REVIEW\\nThe idea of universal language was found in 17th century\\n[3].The concept of translation was base on word-to-word\\ntranslation.\\nWith modern computer and advance computation linguistics\\nman has able to develop automatic machine translation. The\\nEra of modern machine translation started in 1940s and\\nupto 1960 much work was done in advance linguistics[3]. In\\n1966 the Automatic Language Processing Advisory Committee\\n(ALPAC) reported that Machine Translation could not produce\\nquality translations as human translators[3], [2].\\nIn 1980s IBM started work in statistical machine translation\\nand 1990s the parallel text availability had increased the\\ninterest in statistical machine translation. In 2006 an open-\\nsource Statistical Machine Translation tool called Moses was\\nreleased and it currently the most complete Statistical Machine\\nTranslation software available[1].\\nIn 2008 a text/SMS translation service for mobiles was intro-\\nduced in Japan. In 2009 speech-to-speech translation were pro-\\nvided in mobile phone for English, Japanese and Chinese.The\\nNeural machine translation is a new approach to machine\\ntranslation proposed by Kalchbrenner and Blunsom in 2013[4].\\nII. I NTRODUCTION\\nLanguage is medium in which human can express his/her\\nidea. The total estimated language in world are between three\\nthousand to eight thousand. It is very difﬁcult to understand\\nevery language but the languages are the only medium of\\ncommunication in human society. The idea of translation\\nintroduces to communicate messages from one language to\\nothers.\\nMachine Translation (MT)\\nMachine Translation means automatic translation, It the\\nﬁeld of Artiﬁcial Intelligence. Machine translation is computer\\nprogram which is design to translate text from one language\\n(source language) to another language (target language) with-\\nout the help of human. The aim of Machine Translation is to\\nprovide a system that translate text of source language into\\ntarget language and translation express the same meaning as\\nit in source language.\\nGeneral Translation step\\nAny human translation can be described in following steps\\n• Decode the Source Text\\n• Re-encode it into Target language\\nBoth decoding and encode require deep knowledge of source\\nlanguage(SL) and target language (TL). This includes gram-\\nmar, semantic syntax understanding of both languages. Natural\\nLanguage are very complex in term words meaning, grammar\\nrules etc.\\nMachine Translation Approaches\\nThe machine translation approaches are rule-based approach\\nand corpus-based approach. For rule base machine translation,\\nHuman expert deﬁne set of rules for the translation process\\nwhile in corpus base approach rules are automatically ex-\\ntracted.\\n1) Rule-based Machine Translation(RBMT) Approach:The\\nRule-based Machine Translation works on the morphology,\\nsyntax and semantic of both languages. So, we required\\nthe syntax analysis, semantic analysis of Source text and to\\ngenerate the text in target language we need syntax generation\\nand semantic generation. We also need the bilingual dictionary\\nof source and target languages. General Steps of Rule-based\\nMachine Translation are described in ﬁgure 1.\\nFig. 1. Rule-based Machine Translation\\nSub approaches in RBMT\\nThe sub approaches in rule-based Machine translation\\nare direct, transfer-based, interlingual Machine Translation\\napproaches.'), Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\IRT_Machine_Translation.pdf', 'page': 2}, page_content='Direct Machine Translation Approach:\\nThis is oldest approach and translation is performed at word\\nlevel. There is no additional intermediary representation be-\\ntween source and target languages. Words of source language\\ntext is directly translated into the target language. This is\\nuni-directional bilingual translation system. Direct machine\\ntranslation approach involves the word by word translation\\nwith some modiﬁcation at grammar level. The translation is\\nnot good as it is just the replacement of words from target\\nlanguage into source language text i-e word by word meaning\\nreplacement.\\nInterlingual Machine Translation Approach:\\nThis approach introduces an intermediary language represen-\\ntation between source and target languages. This intermediary\\nlanguage is called Neutral Language. Neutral language can\\nrepresent any natural language. It is independent of source and\\ntarget Languages. It is also useful for multilingual translation\\nmachine system.KANT system was developed on interlingual\\napproach in 1992 by Nyberg and Mitamura[5]. Building in-\\nterlingual language is not an easy job. Too much efforts are\\nrequired to develop truly neutral language.\\nTransfer base Machine Translation Approach\\nIn this approach the text of source language is converted\\ninto intermediary representation, it is then used to generate\\nthe target language text with help bilingual dictionary and\\ngrammar rules. Transfer based machine translation process is\\ndivided into three phases.\\nAnalysis\\nIn this phase source language text is analyzed on basis of lin-\\nguistic information and heuristics to parser the text (syntactic\\nrepresentation)\\nTransfer\\nThe syntactic representation of source language is converted\\ninto the syntactic form of target language.\\nGeneration\\nThe ﬁnal text in target language is generate with help of\\nmorphological analysis. This approach heavily dependent on\\nthe grammar and structure of sentence and changes to a\\nmonolingual component affect all transfer modules for that\\nlanguage.\\n2) Corpus-based Machine Translation Approach:It is ac-\\ntually data driven machine translation. It was introduced an\\nalternative approach to the rule-based approach. In this ap-\\nproach the bilanguage parallel corpus is used to extract the\\ntranslation for new sentences. A large amount of raw data\\nis collected in parallel corpora. The raw data is actually the\\ntranslation between source and target languages and this data\\nis used for translation. The sub-approaches of Corpus-based\\nMachine Translation are Statistical Machine Translation and\\nExample-based Machine Translation.\\nStatistical Machine Translation(SMT)\\nThis approach is basis on statistical model. It has two statistical\\nprobabilities models: language model and translation model\\nand massive parallel corpora of source and target languages.\\nThe advantage of SMT system is that linguistic knowledge\\nis not required for building them. The difﬁculty in SMT\\nsystem is creating massive parallel corpus. We have to two\\nmodels in SMT, one is Word-based and other is phrase-based.\\nIn word-bases MT sentences are consider as combination of\\nsingle words and structure relation between the words are\\nignored while in phrase-based model consider sentences as\\ncombination of phrases or chunk. The basic concept in SMT\\nis probability. The probability score of translations are gen-\\nerated from already available translated data (parallel corpus,\\ntranslated by human), the translation having high probability is\\nselected as ﬁnal translation. The probability is calculated with\\nhelp of language and translation models.\\nA huge amount of data is need for SMT and evolved many\\ntraining repetition process. There is also no speciﬁc method\\nquality control of corpora.\\nFig. 2. Statistical Machine Translation\\nExample-based Machine Translation (EBMT)\\nExample-based machine translation contains the point to point\\nmapping between the source and target language sentences i-e\\nwe have examples data that is translated between the source\\nand target language[6]. This data is used for translation. The\\nbasic idea is if already translated sentence occur again it, the\\nsame translation is likely to be correct again. Basically, EBMT\\nis memory-based translation and the concept of analogy is used\\nfor the translation.\\nFig. 3. Example-based Machine Translation\\nIII. C ONCLUSION\\nMany approaches have been proposed but none of them\\nproduce equivalent translation between target and source lan-\\nguages. It is difﬁcult to achieve 100 percent accuracy in trans-\\nlation due the complexity nature of natural Languages. Every\\nnatural language having different sentence structures, grammar\\nand lexicons. However, combining the best feature of different\\napproaches into hybrid approach can improve the accuracy of\\ntranslation. This quality improvement can increase the machine\\ntranslation role in cross-language Information Retrieval System\\nand Multilingual Information Retrieval systems.\\nACKNOWLEDGMENT\\nThe author would like to thank Dr. Arif UR Rehman Bahria\\nUniversity Islamabad.'), Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\IRT_Machine_Translation.pdf', 'page': 3}, page_content='REFERENCES\\n[1] Statistical Machine Translation. http://www.statmt.org/.\\n[2] Translation Automation Timeline. https://www.taus.net/academy/timelines/translation-\\nautomation-timeline.\\n[3] John Hutchins. Machine translation: History and general principles. The\\nencyclopedia of languages and linguistics, 5:2322–2332, 1994.\\n[4] Nal Kalchbrenner and Phil Blunsom. Recurrent continuous translation\\nmodels. In EMNLP, volume 3, page 413, 2013.\\n[5] Eric H. Nyberg and Teruko Mitamura. The kant system: Fast, accurate,\\nhigh-quality translation in practical domains. In Proceedings of the\\n14th Conference on Computational Linguistics - Volume 3, COLING\\n’92, pages 1069–1073, Stroudsburg, PA, USA, 1992. Association for\\nComputational Linguistics.\\n[6] MD Okpor. Machine translation approaches: issues and challenges.\\nInternational Journal of Computer Science Issues (IJCSI), 11(5):159,\\n2014.\\nView publication stats'), Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 0}, page_content='TEXT TO IMAGE GENERATION : L EAVING NO LANGUAGE\\nBEHIND\\nPedro Reviriego\\nUniversidad Politécnica de Madrid\\n28040 Madrid, Spain\\npedro.reviriego@upm.es\\nElena Merino-Gómez\\nUniversidad de Valladolid\\n47011 Valladolid, Spain\\nelena.merino.gomez@uva.es\\nNovember 18, 2022\\nABSTRACT\\nOne of the latest applications of Artiﬁcial Intelligence (AI) is to generate images from natural\\nlanguage descriptions. These generators are now becoming available and achieve impressive results\\nthat have been used for example in the front cover of magazines. As the input to the generators is in\\nthe form of a natural language text, a question that arises immediately is how these models behave\\nwhen the input is written in different languages. In this paper we perform an initial exploration of\\nhow the performance of three popular text-to-image generators depends on the language. The results\\nshow that there is a signiﬁcant performance degradation when using languages other than English,\\nespecially for languages that are not widely used. This observation leads us to discuss different\\nalternatives on how text-to-image generators can be improved so that performance is consistent across\\ndifferent languages. This is fundamental to ensure that this new technology can be used by non-native\\nEnglish speakers and to preserve linguistic diversity.\\n1 Introduction\\nIn the last decade, Artiﬁcial Intelligence (AI) has made signiﬁcant breakthroughs and today outperforms humans in\\na number of tasks. As large datasets for training become available for many applications, and more sophisticated\\nmodels are developed, AI is expected to overtake humans in more tasks in the coming years [1]. One application that\\nhas experience a dramatic improvement in the last years are text-to-image AI generators. These tools take as input\\na natural language description of an image in the form of a text prompt and generate an image that corresponds to\\nwhat is described in the text. A good example are the DALL-E and Glide tools developed by OpenAI [2],[3],[4] or\\nImagen [5] and Parti [6] from Google. There are many other tools such as Cogview [7] and some are available as\\nopen-source projects like Craiyon (formerly DALL-E Mini) [8] or offer publicly available interfaces to generate images\\nlike MidJourney1 or DALL-E2 [3]. These text-to-image generators are attracting a lot of interest in many different\\ncommunities ranging from computer science and graphic designers to artists, and even the general public. A good\\n1Available at www.midjourney.com\\narXiv:2208.09333v2  [cs.CL]  17 Nov 2022'), Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 1}, page_content='A PREPRINT - NOVEMBER 18, 2022\\nexample of this interest is the use of DALL-E2 to create the front cover of a popular magazine2. This interest is expected\\nto drive the development of this technology with new tools or new versions of existing tools being released in the\\ncoming months. These state of the art text-to-image generators are trained with huge datasets and have billions of\\nparameters. For example, the latest Google generator, Parti can have up to 20 billion parameters and is trained on\\nseveral billions of text/image pairs [6]. This means that the training of the generator requires a large computational cost\\nand time.\\nAnother area in which AI has also improved signiﬁcantly is machine translation of texts [9]. Machine translation is now\\nbeing used in many applications and is expected to be adopted in many others in the coming years [10],[11]. Machine\\ntranslation is indeed a key technology to ensure that the latest technologies are available to humans regardless of their\\nlanguage thus ensuring diversity and inclusiveness [12]. Many tools have been implemented and are available for\\nend-users or developers. There are indeed large efforts to make natural language processing in general and machine\\ntranslation in particular, available in many languages. For example, BLOOM3 an advanced large language model with\\nclose to 200 billion parameters and that can generate text in 46 languages has been recently released as an open source\\nproject. As for text-to-image generators, training requires a huge computational effort, indeed more than 100 days\\nrunning on a supercomputer were needed to train BLOOM. Another recent development is the No Language Left\\nBehind (NLLB) initiative by Meta that provides translation among 200 different languages and for which the code has\\nbeen released as open source [9].\\nAs text-to-image generator technology emerges and consolidates, supporting language diversity and inclusiveness will\\nbecome a priority. In this paper we take an initial step in this direction and analyze how current generators performance\\ndepends on the language used to input the text. We consider several generators and languages using simple texts to get\\na preliminary understanding on the state of the technology. These initial results show that for widely used languages,\\nlike Spanish, some of the generators have a similar performance to English, but others suffer a signiﬁcant performance\\ndegradation. Instead, for languages used by smaller communities or no longer used, all the generators have a large\\nperformance degradation in most cases. Based on these results, we brieﬂy discuss how language support can be achieved\\nin text-to-image generators exploring different options. All of them seem to lead to an interaction between text-to-image\\ngenerators and machine translation, opening an interesting topic for further research.\\nThe rest of the paper is organized as follows. In section 2 we describe how we have designed our initial evaluation\\nexperiments and report and discuss the results. Then in section 3 we brieﬂy discuss different options to make the\\nperformance of text-to-image generators consistent across many languages. The paper ends with the conclusion in\\nsection 4.\\n2 Initial Evaluation of Language Support in Text to Image Generators\\nIn order to have a preliminary idea of how different languages are supported on text-to-image generators, an initial\\nevaluation has been done using four languages:\\n1. English.\\n2. Spanish.\\n3. Basque.\\n4. Latin.\\n2Available at www.cosmopolitan.com/lifestyle/a40314356/dall-e-2-artificial-intelligence-cover/\\n3Available at https://huggingface.co/blog/bloom\\n2'), Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 2}, page_content='A PREPRINT - NOVEMBER 18, 2022\\nEnglish is used as the benchmark for comparison; Spanish is included as a broadly used language that has also\\nsimilarities with other Roman languages such as Italian, French or Portuguese; Basque4 as an example of a language\\nused by a small community that has no similarity with any major language; and Latin as an example of a language that\\nis no longer used but has strongly inﬂuenced many widely used languages. The translation of the prompts has been\\ndone using Google translate and then checked and corrected when needed by native speakers and an expert in Latin.\\nIn terms of generators, three commonly used and publicly available tools have been used:\\n1. DALL-E2.\\n2. MidJourney.\\n3. Craiyon.\\nDALL-E2 is a state of the art text-to-image generator developed by OpenAI. DALL-E2 has been trained using several\\nhundreds of millions of text/image pairs and uses an AI model with billions of parameters. The algorithms, datasets and\\nperformance are described in some detail in [3]. MidJourney does not disclose details about the implementation, but\\nit is also publicly available and has issued several releases. In our test we used the implementation available during\\nAugust 2022. Finally, Craiyon (formerly known as DALL-E Mini) is an open-source project that aims to reproduce the\\nresults of OpenAI’s DALL-E with a simpler design. In more detail, Craiyon uses only 0.4 billion parameters in the\\nmodel compared to the several billion of DALL-E2 which makes the training process much faster, and also reduces the\\nstorage requirements and the time needed to generate images. Craiyon was trained with three image/text datasets using\\nin total approximately 15 million image/text pairs.\\nFinally, we have selected ﬁve random text prompts5 from the MS-COCO dataset [13] that have been used to illustrate\\nthe performance of DALL-E2 (see Figure 12 in [3]). These prompts are short and simple sentences and contain only\\ncommon words and thus one would expect a text-to-image generator to be able to create images that relate to the text.\\nThis gives us a total of 60 different sets of images that are sufﬁcient to illustrate how performance varies signiﬁcantly\\nacross languages in current text-to-image generators.\\nThe results obtained for MidJourney are summarized in Figure 1. In this case, four images are shown per text prompt. It\\ncan be observed that for English, the images capture the meaning of the text input reasonably well. For Spanish part of\\nthe information in the text is lost and does not appear in the images. Finally, for Basque and Latin, the tool is unable to\\ninterpret the text and produces images that are completely unrelated to the meaning of the text. Therefore, it seems that\\nthis tool has a performance that depends strongly on the input language even for widely used languages.\\nThe results for Craiyon are presented in Figure 2. This tool produces nine images per run with the default settings, the\\nbest image obtained is shown in the ﬁgure. In this case, the images for Spanish text prompts have a similar quality as\\nthose of English. Instead, results for Basque and Latin are bad, with Craiyon identifying part of the elements described\\nin the text in the best cases and producing completely unrelated images in the rest. Finally, the results for DALL-E2 are\\nshown in Figure 3. The tool generates four images by default and the best one is shown. It can be observed that the\\nquality of the images is similar for English and Spanish. Instead, there is a signiﬁcant performance loss for both Basque\\nand Latin.\\nTherefore, this simple experiment conﬁrms that current text-to-image generation technology does not provide consistent\\nperformance across languages even when using very simple text prompts. Indeed, some of the tools suffer a signiﬁcant\\nperformance degradation even when using widely used languages such as Spanish. The degradation is dramatic for\\n4A \"language isolate\" used in parts of northern Spain that has no demonstrated links with any major language.\\n5The prompts with the translations used for each language are listed in an appendix at the end of the paper.\\n3'), Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 3}, page_content='A PREPRINT - NOVEMBER 18, 2022\\nBasque and Latin. In the ﬁrst case, probably few image/text pairs have been used to train the tools as it is not a widely\\nused language. The second shows that current AI generators cannot infer the meaning of Latin texts even when they\\nhave been trained with multiple languages derived from it such as Spanish, Italian or French.\\n3 Leaving no Language Behind in Text to Image Generation\\nIn this section we brieﬂy discuss possible approaches to achieve similar performance across many languages in\\ntext-to-image generators.\\nThe ﬁrst solution could be to include a relevant number of text/image pairs in all the target languages during the training\\nof the generators. However, this has a number of issues: 1) getting those pairs does not seem to be straightforward\\nand 2) training the model would be signiﬁcantly more complex as the size of the dataset would grow by two orders\\nof magnitude to cover a relevant number of languages. In more detail, there are some efforts to develop datasets of\\nannotated images on several languages (see [14] and references within) but they are limited in the number of languages\\nand number of images, very far from the hundreds of millions or billions used in state of the art text-to-image generators.\\nA potential solution to the lack of annotated images for some languages could be to use automatic machine translation\\nof the English annotations. Indeed, this has shown good performance in previous works such as [15]. However, even if\\nwe can generate many text/image pairs for all the target languages, we would still have to face the second issue, training\\nthe system with a much larger dataset.\\nA second approach would be to add a natural language processing module to the text-to-image generators that detects\\nthe language of the input text and when it corresponds to a language for which the system has poor performance applies\\nmachine translation to English and uses the generated text as input. This has a number of advantages compared to\\nthe previous solution: 1) the text-to-image generator can be trained on a much smaller dataset and 2) the machine\\ntranslation is independent of the text-to-image generator so that advances in translation can be used as they become\\navailable or different implementations of the translation can be used with the same text-to-image generator. Therefore,\\nit seems this second solution is more ﬂexible and scalable.\\nA ﬁnal consideration is that the lack of human annotated images for many languages would in any case limit the ability\\nof text-to-image generators to what can be achieved in translation (that has to be used either in the generation of the\\ntraining dataset or to translate the input text) and thus minority languages would be somewhat lost in translation.\\n4 Conclusion\\nIn this paper we have performed an initial exploration of the performance of several recently developed text-to-image\\ngenerators that are publicly available when using different languages for the text input. The results show that all\\ngenerators suffer a signiﬁcant degradation on the quality of their results when using languages that are not widely used\\nand the degradation is even worse for classical languages such as Latin. Therefore, current generators do not seem\\nto support language diversity and inclusiveness which are fundamental goals to make AI fair and responsible. Based\\non that observation, we have also discussed several alternatives to make the performance of text-to-image generators\\nconsistent across different languages. The analysis suggests that for low resources languages an attractive option is\\nto use machine translation to preprocess the text and convert it to English. In any case, as text-to-image technology\\nis still in its infancy, further evaluation and analysis is needed to fully understand how consistent performance across\\nlanguages can be best achieved.\\n4'), Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 4}, page_content='A PREPRINT - NOVEMBER 18, 2022\\nText prompt 1: “a green train is coming down the tracks” (English, Spanish, Basque, Latin)\\nText prompt 2: “a group of skiers are preparing to ski down a mountain” (English, Spanish, Basque, Latin)\\nText prompt 3: “a small kitchen with a low ceiling” (English, Spanish, Basque, Latin)\\nText prompt 4: “a group of elephants walking in muddy water” (English, Spanish, Basque, Latin)\\nText prompt 5: “a living area with a television and a table” (English, Spanish, Basque, Latin)\\nFigure 1: Results for MidJourney\\n5'), Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 5}, page_content='A PREPRINT - NOVEMBER 18, 2022\\nText prompt 1: “a green train is coming down the tracks” (English, Spanish, Basque, Latin)\\nText prompt 2: “a group of skiers are preparing to ski down a mountain” (English, Spanish, Basque, Latin)\\nText prompt 3: “a small kitchen with a low ceiling” (English, Spanish, Basque, Latin)\\nText prompt 4: “a group of elephants walking in muddy water” (English, Spanish, Basque, Latin)\\nText prompt 5: “a living area with a television and a table” (English, Spanish, Basque, Latin)\\nFigure 2: Results for Craiyon\\n6'), Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 6}, page_content='A PREPRINT - NOVEMBER 18, 2022\\nText prompt 1: “a green train is coming down the tracks” (English, Spanish, Basque, Latin)\\nText prompt 2: “a group of skiers are preparing to ski down a mountain” (English, Spanish, Basque, Latin)\\nText prompt 3: “a small kitchen with a low ceiling” (English, Spanish, Basque, Latin)\\nText prompt 4: “a group of elephants walking in muddy water” (English, Spanish, Basque, Latin)\\nText prompt 5: “a living area with a television and a table” (English, Spanish, Basque, Latin)\\nFigure 3: Results for DALL-E2\\n7'), Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 7}, page_content='A PREPRINT - NOVEMBER 18, 2022\\nReferences\\n[1] K. Grace, J- Salvatier, A. Dafoe, B. Zhang, and O. Evans, Viewpoint: When will AI exceed human performance?\\nEvidence from AI experts. Journal of Artiﬁcial Intelligence Research, 62, 729–754, 2019.\\n[2] A. Ramesh, M. Pavlov, G. Goh, S. Gray, C. V oss, A. Radford, M. Chen, and I. Sutskever. Zero-shot text-to-image\\ngeneration. In International Conference on Machine Learning, pages 8821–8831. PMLR, 2021.\\n[3] A. Ramesh, P. Dhariwal, A. Nichol, C. Chu, and M. Chen. Hierarchical text-conditional image generation with clip\\nlatents. arXiv preprint arXiv:2204.06125, 2022.\\n[4] A. Nichol, P. Dhariwal, A. Ramesh, P. Shyam, P. Mishkin, B. McGrew, I. Sutskever, and M. Chen. Glide: Towards\\nphotorealistic image generation and editing with text-guided diffusion models. arXiv preprint arXiv:2112.10741,\\n2021.\\n[5] C. Saharia, W. Chan, S. Saxena, L. Li, J. Whang, E. Denton, S. Kamyar, S. Ghasemipour, B. Karagol, S. Sara\\nMahdavi, R. Gontijo-Lopes, T. Salimans, J. Ho, D. J Fleet, and M. Norouzi. Photorealistic text-to-image diffusion\\nmodels with deep language understanding. arXiv preprint arXiv:2205.11487, 2022.\\n[6] J. Yu, Y . Xu, J. Koh, T. Luong, G. Baid, Z. Wang, V . Vasudevan, A. Ku Y . Yang, B. Ayan, B. Hutchinson, W. Wei,\\nZ. Parekh, X. Li, H. Zhang, J. Baldridge and Y . Wu Yonghui. Scaling Autoregressive Models for Content-Rich\\nText-to-Image Generation, arXiv preprint arXiv:2206.10789, 2022.\\n[7] D. Ming Ding et al. Cogview: Mastering text-to-image generation via transformers. Advances in Neural Information\\nProcessing Systems, 34, 2021.\\n[8] B. Dayma, S. Patil, P. Cuenca, K. Saifullah, T. Abraham, P. Le Khac, L. Melas, R. Ghosh. DALL ·E Mini,\\nhttps://github.com/borisdayma/dalle-mini, 2021.\\n[9] NLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, https://arxiv.\\norg/abs/2207.04672.\\n[10] E.C. Khoong and J.A. Rodriguez. A Research Agenda for Using Machine Translation in Clinical Medicine. J.\\nGen Intern Med 37, 1275–1277 (2022).\\n[11] 11. Sangmin-Michelle Lee. The impact of using machine translation on eﬂ students’ writing. Computer Assisted\\nLanguage Learning, 33(3):157–175, 2020.\\n[12] A. Fan, et al. \"Beyond English-Centric Multilingual Machine Translation.\" J. Mach. Learn. Res. 22.107 (2021):\\n1-48.\\n[13] T, Lin, M. Maire, S. Belongie, L. Bourdev, R. Girshick, J. Hays, P. Perona, D. Ramanan, C. L. Zitnick, and Piotr\\nDollár. Microsoft COCO: Common Objects in Context. arXiv:1405.0312, 2014.\\n[14] S. Koeva, I. Stoyanova and J. Kralev. Multilingual Image Corpus – Towards a Multimodal and Multilingual\\nDataset, 13th Language Resources and Evaluation Conference, 2022.\\n[15] A. Burns et al. \"Learning to scale multilingual representations for vision-language tasks.\" European Conference\\non Computer Vision, 2020.\\n8'), Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 8}, page_content='A PREPRINT - NOVEMBER 18, 2022\\nAPPENDIX: Text Prompts\\nThe text prompts used in the different languages (English, Spanish, Basque, Latin6 ) are:\\n1. \"a green train is coming down the tracks”, \"un tren verde viene por las vías\", \"tren berde bat dator trenbideetatik\\nbehera\", \"viridis hamaxósticus ferrivia venit\"\\n2. “a group of skiers are preparing to ski down a mountain”, \"un grupo de esquiadores se prepara para esquiar\\nmontaña abajo\", \"eskiatzaile talde bat menditik behera eskiatzeko prestatzen ari da\", \"nartatorum turma parat\\nnartis prolabi a monte\"\\n3. “a small kitchen with a low ceiling”, “una pequeña cocina con un techo bajo”, \"sukalde txiki bat sabai\\nbaxuarekin\", \"parva coquina humili tecto\"\\n4. “a group of elephants walking in muddy water”, \"un grupo de elefantes caminando en agua fangosas\", \"elefante\\ntalde bat ur zingiratsuetan ibiltzen\", \"multitudo elephantorum ambulans in turbida aqua”\\n5. “a living area with a television and a table”, \"una sala de estar con un televisor y una mesa\", \"egongela bat\\ntelebista con mahai batekin\" Ban eta \"egongela bat telebista eta mahai batekin\", \"oecus televisione et mensa\"\\n6For Latin, new words were taken from “Lexicon Recentis Latinitatis”. 2 vols. Vaticano: Libraria Editoria Vaticana, vol I: 1982;\\nvol II: 1997 and Egger, Carolus. “Sermo Latinus Hodiernus”, Roma: Opus Fundatum “Latinitas”, 1986.\\n9')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import os\n",
    "\n",
    "path = r'D:\\Programming\\Summarize-PDF'\n",
    "documents = []\n",
    "for pdf_file in os.listdir('D:/Programming/Summarize-PDF'):\n",
    "    #print(pdf_file)\n",
    "    if pdf_file.endswith(\".pdf\"):\n",
    "        #print(pdf_file)\n",
    "        pdf_path_join = os.path.join(path,pdf_file)\n",
    "        loader = PyPDFLoader(pdf_path_join)\n",
    "        for doc in loader.lazy_load():\n",
    "            #print(doc)\n",
    "            documents.append(doc)\n",
    "            \n",
    "        \n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "chunk = RecursiveCharacterTextSplitter( chunk_size = 1000, chunk_overlap = False)\n",
    "split_pdf = chunk.split_documents(documents)\n",
    "len(split_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\IRT_Machine_Translation.pdf', 'page': 0}, page_content='See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/320730405\\nMachine Translation\\nPreprint · October 2017\\nCITATIONS\\n0\\nREADS\\n38,236\\n1 author:\\nMuhammad Irfan\\nBahria University\\n1 PUBLICATION\\xa0\\xa0\\xa00 CITATIONS\\xa0\\xa0\\xa0\\nSEE PROFILE\\nAll content following this page was uploaded by Muhammad Irfan on 31 October 2017.\\nThe user has requested enhancement of the downloaded file.'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\IRT_Machine_Translation.pdf', 'page': 1}, page_content='Machine Translation\\nMuhammad Irfan\\nDepartment of Computer Science\\nBahria University Islamabad\\nEmail: muhammad.Irfan@outlook.com\\nAbstract—Language is core medium of communication and\\ntranslation is core tool for the understand the information\\nin unknown language.Machine translation helps the people to\\nunderstand the information of unknown language without the\\nhelp of Human translator. This study is brief introduction to\\nmachine translation.\\nKeywords— Machine Translation, Rule-base Machine Transla-\\ntion, Example-base Machine Translation, Statistical Machine.\\nI. L ITERATURE REVIEW\\nThe idea of universal language was found in 17th century\\n[3].The concept of translation was base on word-to-word\\ntranslation.\\nWith modern computer and advance computation linguistics\\nman has able to develop automatic machine translation. The\\nEra of modern machine translation started in 1940s and\\nupto 1960 much work was done in advance linguistics[3]. In\\n1966 the Automatic Language Processing Advisory Committee'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\IRT_Machine_Translation.pdf', 'page': 1}, page_content='(ALPAC) reported that Machine Translation could not produce\\nquality translations as human translators[3], [2].\\nIn 1980s IBM started work in statistical machine translation\\nand 1990s the parallel text availability had increased the\\ninterest in statistical machine translation. In 2006 an open-\\nsource Statistical Machine Translation tool called Moses was\\nreleased and it currently the most complete Statistical Machine\\nTranslation software available[1].\\nIn 2008 a text/SMS translation service for mobiles was intro-\\nduced in Japan. In 2009 speech-to-speech translation were pro-\\nvided in mobile phone for English, Japanese and Chinese.The\\nNeural machine translation is a new approach to machine\\ntranslation proposed by Kalchbrenner and Blunsom in 2013[4].\\nII. I NTRODUCTION\\nLanguage is medium in which human can express his/her\\nidea. The total estimated language in world are between three\\nthousand to eight thousand. It is very difﬁcult to understand'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\IRT_Machine_Translation.pdf', 'page': 1}, page_content='every language but the languages are the only medium of\\ncommunication in human society. The idea of translation\\nintroduces to communicate messages from one language to\\nothers.\\nMachine Translation (MT)\\nMachine Translation means automatic translation, It the\\nﬁeld of Artiﬁcial Intelligence. Machine translation is computer\\nprogram which is design to translate text from one language\\n(source language) to another language (target language) with-\\nout the help of human. The aim of Machine Translation is to\\nprovide a system that translate text of source language into\\ntarget language and translation express the same meaning as\\nit in source language.\\nGeneral Translation step\\nAny human translation can be described in following steps\\n• Decode the Source Text\\n• Re-encode it into Target language\\nBoth decoding and encode require deep knowledge of source\\nlanguage(SL) and target language (TL). This includes gram-\\nmar, semantic syntax understanding of both languages. Natural'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\IRT_Machine_Translation.pdf', 'page': 1}, page_content='Language are very complex in term words meaning, grammar\\nrules etc.\\nMachine Translation Approaches\\nThe machine translation approaches are rule-based approach\\nand corpus-based approach. For rule base machine translation,\\nHuman expert deﬁne set of rules for the translation process\\nwhile in corpus base approach rules are automatically ex-\\ntracted.\\n1) Rule-based Machine Translation(RBMT) Approach:The\\nRule-based Machine Translation works on the morphology,\\nsyntax and semantic of both languages. So, we required\\nthe syntax analysis, semantic analysis of Source text and to\\ngenerate the text in target language we need syntax generation\\nand semantic generation. We also need the bilingual dictionary\\nof source and target languages. General Steps of Rule-based\\nMachine Translation are described in ﬁgure 1.\\nFig. 1. Rule-based Machine Translation\\nSub approaches in RBMT\\nThe sub approaches in rule-based Machine translation\\nare direct, transfer-based, interlingual Machine Translation\\napproaches.'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\IRT_Machine_Translation.pdf', 'page': 2}, page_content='Direct Machine Translation Approach:\\nThis is oldest approach and translation is performed at word\\nlevel. There is no additional intermediary representation be-\\ntween source and target languages. Words of source language\\ntext is directly translated into the target language. This is\\nuni-directional bilingual translation system. Direct machine\\ntranslation approach involves the word by word translation\\nwith some modiﬁcation at grammar level. The translation is\\nnot good as it is just the replacement of words from target\\nlanguage into source language text i-e word by word meaning\\nreplacement.\\nInterlingual Machine Translation Approach:\\nThis approach introduces an intermediary language represen-\\ntation between source and target languages. This intermediary\\nlanguage is called Neutral Language. Neutral language can\\nrepresent any natural language. It is independent of source and\\ntarget Languages. It is also useful for multilingual translation'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\IRT_Machine_Translation.pdf', 'page': 2}, page_content='machine system.KANT system was developed on interlingual\\napproach in 1992 by Nyberg and Mitamura[5]. Building in-\\nterlingual language is not an easy job. Too much efforts are\\nrequired to develop truly neutral language.\\nTransfer base Machine Translation Approach\\nIn this approach the text of source language is converted\\ninto intermediary representation, it is then used to generate\\nthe target language text with help bilingual dictionary and\\ngrammar rules. Transfer based machine translation process is\\ndivided into three phases.\\nAnalysis\\nIn this phase source language text is analyzed on basis of lin-\\nguistic information and heuristics to parser the text (syntactic\\nrepresentation)\\nTransfer\\nThe syntactic representation of source language is converted\\ninto the syntactic form of target language.\\nGeneration\\nThe ﬁnal text in target language is generate with help of\\nmorphological analysis. This approach heavily dependent on\\nthe grammar and structure of sentence and changes to a'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\IRT_Machine_Translation.pdf', 'page': 2}, page_content='monolingual component affect all transfer modules for that\\nlanguage.\\n2) Corpus-based Machine Translation Approach:It is ac-\\ntually data driven machine translation. It was introduced an\\nalternative approach to the rule-based approach. In this ap-\\nproach the bilanguage parallel corpus is used to extract the\\ntranslation for new sentences. A large amount of raw data\\nis collected in parallel corpora. The raw data is actually the\\ntranslation between source and target languages and this data\\nis used for translation. The sub-approaches of Corpus-based\\nMachine Translation are Statistical Machine Translation and\\nExample-based Machine Translation.\\nStatistical Machine Translation(SMT)\\nThis approach is basis on statistical model. It has two statistical\\nprobabilities models: language model and translation model\\nand massive parallel corpora of source and target languages.\\nThe advantage of SMT system is that linguistic knowledge\\nis not required for building them. The difﬁculty in SMT'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\IRT_Machine_Translation.pdf', 'page': 2}, page_content='system is creating massive parallel corpus. We have to two\\nmodels in SMT, one is Word-based and other is phrase-based.\\nIn word-bases MT sentences are consider as combination of\\nsingle words and structure relation between the words are\\nignored while in phrase-based model consider sentences as\\ncombination of phrases or chunk. The basic concept in SMT\\nis probability. The probability score of translations are gen-\\nerated from already available translated data (parallel corpus,\\ntranslated by human), the translation having high probability is\\nselected as ﬁnal translation. The probability is calculated with\\nhelp of language and translation models.\\nA huge amount of data is need for SMT and evolved many\\ntraining repetition process. There is also no speciﬁc method\\nquality control of corpora.\\nFig. 2. Statistical Machine Translation\\nExample-based Machine Translation (EBMT)\\nExample-based machine translation contains the point to point\\nmapping between the source and target language sentences i-e'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\IRT_Machine_Translation.pdf', 'page': 2}, page_content='we have examples data that is translated between the source\\nand target language[6]. This data is used for translation. The\\nbasic idea is if already translated sentence occur again it, the\\nsame translation is likely to be correct again. Basically, EBMT\\nis memory-based translation and the concept of analogy is used\\nfor the translation.\\nFig. 3. Example-based Machine Translation\\nIII. C ONCLUSION\\nMany approaches have been proposed but none of them\\nproduce equivalent translation between target and source lan-\\nguages. It is difﬁcult to achieve 100 percent accuracy in trans-\\nlation due the complexity nature of natural Languages. Every\\nnatural language having different sentence structures, grammar\\nand lexicons. However, combining the best feature of different\\napproaches into hybrid approach can improve the accuracy of\\ntranslation. This quality improvement can increase the machine\\ntranslation role in cross-language Information Retrieval System\\nand Multilingual Information Retrieval systems.'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\IRT_Machine_Translation.pdf', 'page': 2}, page_content='ACKNOWLEDGMENT\\nThe author would like to thank Dr. Arif UR Rehman Bahria\\nUniversity Islamabad.'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\IRT_Machine_Translation.pdf', 'page': 3}, page_content='REFERENCES\\n[1] Statistical Machine Translation. http://www.statmt.org/.\\n[2] Translation Automation Timeline. https://www.taus.net/academy/timelines/translation-\\nautomation-timeline.\\n[3] John Hutchins. Machine translation: History and general principles. The\\nencyclopedia of languages and linguistics, 5:2322–2332, 1994.\\n[4] Nal Kalchbrenner and Phil Blunsom. Recurrent continuous translation\\nmodels. In EMNLP, volume 3, page 413, 2013.\\n[5] Eric H. Nyberg and Teruko Mitamura. The kant system: Fast, accurate,\\nhigh-quality translation in practical domains. In Proceedings of the\\n14th Conference on Computational Linguistics - Volume 3, COLING\\n’92, pages 1069–1073, Stroudsburg, PA, USA, 1992. Association for\\nComputational Linguistics.\\n[6] MD Okpor. Machine translation approaches: issues and challenges.\\nInternational Journal of Computer Science Issues (IJCSI), 11(5):159,\\n2014.\\nView publication stats'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 0}, page_content='TEXT TO IMAGE GENERATION : L EAVING NO LANGUAGE\\nBEHIND\\nPedro Reviriego\\nUniversidad Politécnica de Madrid\\n28040 Madrid, Spain\\npedro.reviriego@upm.es\\nElena Merino-Gómez\\nUniversidad de Valladolid\\n47011 Valladolid, Spain\\nelena.merino.gomez@uva.es\\nNovember 18, 2022\\nABSTRACT\\nOne of the latest applications of Artiﬁcial Intelligence (AI) is to generate images from natural\\nlanguage descriptions. These generators are now becoming available and achieve impressive results\\nthat have been used for example in the front cover of magazines. As the input to the generators is in\\nthe form of a natural language text, a question that arises immediately is how these models behave\\nwhen the input is written in different languages. In this paper we perform an initial exploration of\\nhow the performance of three popular text-to-image generators depends on the language. The results\\nshow that there is a signiﬁcant performance degradation when using languages other than English,'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 0}, page_content='especially for languages that are not widely used. This observation leads us to discuss different\\nalternatives on how text-to-image generators can be improved so that performance is consistent across\\ndifferent languages. This is fundamental to ensure that this new technology can be used by non-native\\nEnglish speakers and to preserve linguistic diversity.\\n1 Introduction\\nIn the last decade, Artiﬁcial Intelligence (AI) has made signiﬁcant breakthroughs and today outperforms humans in\\na number of tasks. As large datasets for training become available for many applications, and more sophisticated\\nmodels are developed, AI is expected to overtake humans in more tasks in the coming years [1]. One application that\\nhas experience a dramatic improvement in the last years are text-to-image AI generators. These tools take as input\\na natural language description of an image in the form of a text prompt and generate an image that corresponds to'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 0}, page_content='what is described in the text. A good example are the DALL-E and Glide tools developed by OpenAI [2],[3],[4] or\\nImagen [5] and Parti [6] from Google. There are many other tools such as Cogview [7] and some are available as\\nopen-source projects like Craiyon (formerly DALL-E Mini) [8] or offer publicly available interfaces to generate images\\nlike MidJourney1 or DALL-E2 [3]. These text-to-image generators are attracting a lot of interest in many different\\ncommunities ranging from computer science and graphic designers to artists, and even the general public. A good\\n1Available at www.midjourney.com\\narXiv:2208.09333v2  [cs.CL]  17 Nov 2022'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 1}, page_content='A PREPRINT - NOVEMBER 18, 2022\\nexample of this interest is the use of DALL-E2 to create the front cover of a popular magazine2. This interest is expected\\nto drive the development of this technology with new tools or new versions of existing tools being released in the\\ncoming months. These state of the art text-to-image generators are trained with huge datasets and have billions of\\nparameters. For example, the latest Google generator, Parti can have up to 20 billion parameters and is trained on\\nseveral billions of text/image pairs [6]. This means that the training of the generator requires a large computational cost\\nand time.\\nAnother area in which AI has also improved signiﬁcantly is machine translation of texts [9]. Machine translation is now\\nbeing used in many applications and is expected to be adopted in many others in the coming years [10],[11]. Machine\\ntranslation is indeed a key technology to ensure that the latest technologies are available to humans regardless of their'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 1}, page_content='language thus ensuring diversity and inclusiveness [12]. Many tools have been implemented and are available for\\nend-users or developers. There are indeed large efforts to make natural language processing in general and machine\\ntranslation in particular, available in many languages. For example, BLOOM3 an advanced large language model with\\nclose to 200 billion parameters and that can generate text in 46 languages has been recently released as an open source\\nproject. As for text-to-image generators, training requires a huge computational effort, indeed more than 100 days\\nrunning on a supercomputer were needed to train BLOOM. Another recent development is the No Language Left\\nBehind (NLLB) initiative by Meta that provides translation among 200 different languages and for which the code has\\nbeen released as open source [9].\\nAs text-to-image generator technology emerges and consolidates, supporting language diversity and inclusiveness will'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 1}, page_content='become a priority. In this paper we take an initial step in this direction and analyze how current generators performance\\ndepends on the language used to input the text. We consider several generators and languages using simple texts to get\\na preliminary understanding on the state of the technology. These initial results show that for widely used languages,\\nlike Spanish, some of the generators have a similar performance to English, but others suffer a signiﬁcant performance\\ndegradation. Instead, for languages used by smaller communities or no longer used, all the generators have a large\\nperformance degradation in most cases. Based on these results, we brieﬂy discuss how language support can be achieved\\nin text-to-image generators exploring different options. All of them seem to lead to an interaction between text-to-image\\ngenerators and machine translation, opening an interesting topic for further research.'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 1}, page_content='The rest of the paper is organized as follows. In section 2 we describe how we have designed our initial evaluation\\nexperiments and report and discuss the results. Then in section 3 we brieﬂy discuss different options to make the\\nperformance of text-to-image generators consistent across many languages. The paper ends with the conclusion in\\nsection 4.\\n2 Initial Evaluation of Language Support in Text to Image Generators\\nIn order to have a preliminary idea of how different languages are supported on text-to-image generators, an initial\\nevaluation has been done using four languages:\\n1. English.\\n2. Spanish.\\n3. Basque.\\n4. Latin.\\n2Available at www.cosmopolitan.com/lifestyle/a40314356/dall-e-2-artificial-intelligence-cover/\\n3Available at https://huggingface.co/blog/bloom\\n2'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 2}, page_content='A PREPRINT - NOVEMBER 18, 2022\\nEnglish is used as the benchmark for comparison; Spanish is included as a broadly used language that has also\\nsimilarities with other Roman languages such as Italian, French or Portuguese; Basque4 as an example of a language\\nused by a small community that has no similarity with any major language; and Latin as an example of a language that\\nis no longer used but has strongly inﬂuenced many widely used languages. The translation of the prompts has been\\ndone using Google translate and then checked and corrected when needed by native speakers and an expert in Latin.\\nIn terms of generators, three commonly used and publicly available tools have been used:\\n1. DALL-E2.\\n2. MidJourney.\\n3. Craiyon.\\nDALL-E2 is a state of the art text-to-image generator developed by OpenAI. DALL-E2 has been trained using several\\nhundreds of millions of text/image pairs and uses an AI model with billions of parameters. The algorithms, datasets and'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 2}, page_content='performance are described in some detail in [3]. MidJourney does not disclose details about the implementation, but\\nit is also publicly available and has issued several releases. In our test we used the implementation available during\\nAugust 2022. Finally, Craiyon (formerly known as DALL-E Mini) is an open-source project that aims to reproduce the\\nresults of OpenAI’s DALL-E with a simpler design. In more detail, Craiyon uses only 0.4 billion parameters in the\\nmodel compared to the several billion of DALL-E2 which makes the training process much faster, and also reduces the\\nstorage requirements and the time needed to generate images. Craiyon was trained with three image/text datasets using\\nin total approximately 15 million image/text pairs.\\nFinally, we have selected ﬁve random text prompts5 from the MS-COCO dataset [13] that have been used to illustrate\\nthe performance of DALL-E2 (see Figure 12 in [3]). These prompts are short and simple sentences and contain only'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 2}, page_content='common words and thus one would expect a text-to-image generator to be able to create images that relate to the text.\\nThis gives us a total of 60 different sets of images that are sufﬁcient to illustrate how performance varies signiﬁcantly\\nacross languages in current text-to-image generators.\\nThe results obtained for MidJourney are summarized in Figure 1. In this case, four images are shown per text prompt. It\\ncan be observed that for English, the images capture the meaning of the text input reasonably well. For Spanish part of\\nthe information in the text is lost and does not appear in the images. Finally, for Basque and Latin, the tool is unable to\\ninterpret the text and produces images that are completely unrelated to the meaning of the text. Therefore, it seems that\\nthis tool has a performance that depends strongly on the input language even for widely used languages.'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 2}, page_content='The results for Craiyon are presented in Figure 2. This tool produces nine images per run with the default settings, the\\nbest image obtained is shown in the ﬁgure. In this case, the images for Spanish text prompts have a similar quality as\\nthose of English. Instead, results for Basque and Latin are bad, with Craiyon identifying part of the elements described\\nin the text in the best cases and producing completely unrelated images in the rest. Finally, the results for DALL-E2 are\\nshown in Figure 3. The tool generates four images by default and the best one is shown. It can be observed that the\\nquality of the images is similar for English and Spanish. Instead, there is a signiﬁcant performance loss for both Basque\\nand Latin.\\nTherefore, this simple experiment conﬁrms that current text-to-image generation technology does not provide consistent\\nperformance across languages even when using very simple text prompts. Indeed, some of the tools suffer a signiﬁcant'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 2}, page_content='performance degradation even when using widely used languages such as Spanish. The degradation is dramatic for\\n4A \"language isolate\" used in parts of northern Spain that has no demonstrated links with any major language.\\n5The prompts with the translations used for each language are listed in an appendix at the end of the paper.\\n3'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 3}, page_content='A PREPRINT - NOVEMBER 18, 2022\\nBasque and Latin. In the ﬁrst case, probably few image/text pairs have been used to train the tools as it is not a widely\\nused language. The second shows that current AI generators cannot infer the meaning of Latin texts even when they\\nhave been trained with multiple languages derived from it such as Spanish, Italian or French.\\n3 Leaving no Language Behind in Text to Image Generation\\nIn this section we brieﬂy discuss possible approaches to achieve similar performance across many languages in\\ntext-to-image generators.\\nThe ﬁrst solution could be to include a relevant number of text/image pairs in all the target languages during the training\\nof the generators. However, this has a number of issues: 1) getting those pairs does not seem to be straightforward\\nand 2) training the model would be signiﬁcantly more complex as the size of the dataset would grow by two orders'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 3}, page_content='of magnitude to cover a relevant number of languages. In more detail, there are some efforts to develop datasets of\\nannotated images on several languages (see [14] and references within) but they are limited in the number of languages\\nand number of images, very far from the hundreds of millions or billions used in state of the art text-to-image generators.\\nA potential solution to the lack of annotated images for some languages could be to use automatic machine translation\\nof the English annotations. Indeed, this has shown good performance in previous works such as [15]. However, even if\\nwe can generate many text/image pairs for all the target languages, we would still have to face the second issue, training\\nthe system with a much larger dataset.\\nA second approach would be to add a natural language processing module to the text-to-image generators that detects\\nthe language of the input text and when it corresponds to a language for which the system has poor performance applies'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 3}, page_content='machine translation to English and uses the generated text as input. This has a number of advantages compared to\\nthe previous solution: 1) the text-to-image generator can be trained on a much smaller dataset and 2) the machine\\ntranslation is independent of the text-to-image generator so that advances in translation can be used as they become\\navailable or different implementations of the translation can be used with the same text-to-image generator. Therefore,\\nit seems this second solution is more ﬂexible and scalable.\\nA ﬁnal consideration is that the lack of human annotated images for many languages would in any case limit the ability\\nof text-to-image generators to what can be achieved in translation (that has to be used either in the generation of the\\ntraining dataset or to translate the input text) and thus minority languages would be somewhat lost in translation.\\n4 Conclusion'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 3}, page_content='In this paper we have performed an initial exploration of the performance of several recently developed text-to-image\\ngenerators that are publicly available when using different languages for the text input. The results show that all\\ngenerators suffer a signiﬁcant degradation on the quality of their results when using languages that are not widely used\\nand the degradation is even worse for classical languages such as Latin. Therefore, current generators do not seem\\nto support language diversity and inclusiveness which are fundamental goals to make AI fair and responsible. Based\\non that observation, we have also discussed several alternatives to make the performance of text-to-image generators\\nconsistent across different languages. The analysis suggests that for low resources languages an attractive option is\\nto use machine translation to preprocess the text and convert it to English. In any case, as text-to-image technology'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 3}, page_content='is still in its infancy, further evaluation and analysis is needed to fully understand how consistent performance across\\nlanguages can be best achieved.\\n4'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 4}, page_content='A PREPRINT - NOVEMBER 18, 2022\\nText prompt 1: “a green train is coming down the tracks” (English, Spanish, Basque, Latin)\\nText prompt 2: “a group of skiers are preparing to ski down a mountain” (English, Spanish, Basque, Latin)\\nText prompt 3: “a small kitchen with a low ceiling” (English, Spanish, Basque, Latin)\\nText prompt 4: “a group of elephants walking in muddy water” (English, Spanish, Basque, Latin)\\nText prompt 5: “a living area with a television and a table” (English, Spanish, Basque, Latin)\\nFigure 1: Results for MidJourney\\n5'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 5}, page_content='A PREPRINT - NOVEMBER 18, 2022\\nText prompt 1: “a green train is coming down the tracks” (English, Spanish, Basque, Latin)\\nText prompt 2: “a group of skiers are preparing to ski down a mountain” (English, Spanish, Basque, Latin)\\nText prompt 3: “a small kitchen with a low ceiling” (English, Spanish, Basque, Latin)\\nText prompt 4: “a group of elephants walking in muddy water” (English, Spanish, Basque, Latin)\\nText prompt 5: “a living area with a television and a table” (English, Spanish, Basque, Latin)\\nFigure 2: Results for Craiyon\\n6'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 6}, page_content='A PREPRINT - NOVEMBER 18, 2022\\nText prompt 1: “a green train is coming down the tracks” (English, Spanish, Basque, Latin)\\nText prompt 2: “a group of skiers are preparing to ski down a mountain” (English, Spanish, Basque, Latin)\\nText prompt 3: “a small kitchen with a low ceiling” (English, Spanish, Basque, Latin)\\nText prompt 4: “a group of elephants walking in muddy water” (English, Spanish, Basque, Latin)\\nText prompt 5: “a living area with a television and a table” (English, Spanish, Basque, Latin)\\nFigure 3: Results for DALL-E2\\n7'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 7}, page_content='A PREPRINT - NOVEMBER 18, 2022\\nReferences\\n[1] K. Grace, J- Salvatier, A. Dafoe, B. Zhang, and O. Evans, Viewpoint: When will AI exceed human performance?\\nEvidence from AI experts. Journal of Artiﬁcial Intelligence Research, 62, 729–754, 2019.\\n[2] A. Ramesh, M. Pavlov, G. Goh, S. Gray, C. V oss, A. Radford, M. Chen, and I. Sutskever. Zero-shot text-to-image\\ngeneration. In International Conference on Machine Learning, pages 8821–8831. PMLR, 2021.\\n[3] A. Ramesh, P. Dhariwal, A. Nichol, C. Chu, and M. Chen. Hierarchical text-conditional image generation with clip\\nlatents. arXiv preprint arXiv:2204.06125, 2022.\\n[4] A. Nichol, P. Dhariwal, A. Ramesh, P. Shyam, P. Mishkin, B. McGrew, I. Sutskever, and M. Chen. Glide: Towards\\nphotorealistic image generation and editing with text-guided diffusion models. arXiv preprint arXiv:2112.10741,\\n2021.\\n[5] C. Saharia, W. Chan, S. Saxena, L. Li, J. Whang, E. Denton, S. Kamyar, S. Ghasemipour, B. Karagol, S. Sara'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 7}, page_content='Mahdavi, R. Gontijo-Lopes, T. Salimans, J. Ho, D. J Fleet, and M. Norouzi. Photorealistic text-to-image diffusion\\nmodels with deep language understanding. arXiv preprint arXiv:2205.11487, 2022.\\n[6] J. Yu, Y . Xu, J. Koh, T. Luong, G. Baid, Z. Wang, V . Vasudevan, A. Ku Y . Yang, B. Ayan, B. Hutchinson, W. Wei,\\nZ. Parekh, X. Li, H. Zhang, J. Baldridge and Y . Wu Yonghui. Scaling Autoregressive Models for Content-Rich\\nText-to-Image Generation, arXiv preprint arXiv:2206.10789, 2022.\\n[7] D. Ming Ding et al. Cogview: Mastering text-to-image generation via transformers. Advances in Neural Information\\nProcessing Systems, 34, 2021.\\n[8] B. Dayma, S. Patil, P. Cuenca, K. Saifullah, T. Abraham, P. Le Khac, L. Melas, R. Ghosh. DALL ·E Mini,\\nhttps://github.com/borisdayma/dalle-mini, 2021.\\n[9] NLLB Team et al, No Language Left Behind: Scaling Human-Centered Machine Translation, https://arxiv.\\norg/abs/2207.04672.'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 7}, page_content='[10] E.C. Khoong and J.A. Rodriguez. A Research Agenda for Using Machine Translation in Clinical Medicine. J.\\nGen Intern Med 37, 1275–1277 (2022).\\n[11] 11. Sangmin-Michelle Lee. The impact of using machine translation on eﬂ students’ writing. Computer Assisted\\nLanguage Learning, 33(3):157–175, 2020.\\n[12] A. Fan, et al. \"Beyond English-Centric Multilingual Machine Translation.\" J. Mach. Learn. Res. 22.107 (2021):\\n1-48.\\n[13] T, Lin, M. Maire, S. Belongie, L. Bourdev, R. Girshick, J. Hays, P. Perona, D. Ramanan, C. L. Zitnick, and Piotr\\nDollár. Microsoft COCO: Common Objects in Context. arXiv:1405.0312, 2014.\\n[14] S. Koeva, I. Stoyanova and J. Kralev. Multilingual Image Corpus – Towards a Multimodal and Multilingual\\nDataset, 13th Language Resources and Evaluation Conference, 2022.\\n[15] A. Burns et al. \"Learning to scale multilingual representations for vision-language tasks.\" European Conference\\non Computer Vision, 2020.\\n8'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 8}, page_content='A PREPRINT - NOVEMBER 18, 2022\\nAPPENDIX: Text Prompts\\nThe text prompts used in the different languages (English, Spanish, Basque, Latin6 ) are:\\n1. \"a green train is coming down the tracks”, \"un tren verde viene por las vías\", \"tren berde bat dator trenbideetatik\\nbehera\", \"viridis hamaxósticus ferrivia venit\"\\n2. “a group of skiers are preparing to ski down a mountain”, \"un grupo de esquiadores se prepara para esquiar\\nmontaña abajo\", \"eskiatzaile talde bat menditik behera eskiatzeko prestatzen ari da\", \"nartatorum turma parat\\nnartis prolabi a monte\"\\n3. “a small kitchen with a low ceiling”, “una pequeña cocina con un techo bajo”, \"sukalde txiki bat sabai\\nbaxuarekin\", \"parva coquina humili tecto\"\\n4. “a group of elephants walking in muddy water”, \"un grupo de elefantes caminando en agua fangosas\", \"elefante\\ntalde bat ur zingiratsuetan ibiltzen\", \"multitudo elephantorum ambulans in turbida aqua”'),\n",
       " Document(metadata={'source': 'D:\\\\Programming\\\\Summarize-PDF\\\\texttoimage.pdf', 'page': 8}, page_content='5. “a living area with a television and a table”, \"una sala de estar con un televisor y una mesa\", \"egongela bat\\ntelebista con mahai batekin\" Ban eta \"egongela bat telebista eta mahai batekin\", \"oecus televisione et mensa\"\\n6For Latin, new words were taken from “Lexicon Recentis Latinitatis”. 2 vols. Vaticano: Libraria Editoria Vaticana, vol I: 1982;\\nvol II: 1997 and Egger, Carolus. “Sermo Latinus Hodiernus”, Roma: Opus Fundatum “Latinitas”, 1986.\\n9')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14388\\1441196560.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  db = FAISS.from_documents(documents=split_pdf, embedding=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "db = FAISS.from_documents(documents=split_pdf, embedding=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"))\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatGroq(temperature = 0.1, model_name = \"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a PDF Reader Assistant.\"\n",
    "    \"Provide concise and professional responses.\"\n",
    "    \"If the user asks a part of PDF, give clear and helpful information about it.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\",system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "create_stuff_documents_chain = create_stuff_documents_chain(model,prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "output = create_retrieval_chain(retriever, create_stuff_documents_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The text you provided appears to be a snippet from a research paper on machine translation, specifically focusing on text-to-image generators and their performance across different languages. \\n\\nThe two main topics discussed are:\\n\\n1. **Initial Evaluation of Language Support in Text to Image Generators**: The author conducted an initial evaluation of how well text-to-image generators support different languages, using four languages: English, Spanish, Basque, and Latin. They used five text prompts to test the generators.\\n\\n2. **Options to Improve Performance**: The author briefly discusses options to make the performance of text-to-image generators consistent across many languages, although the details of this discussion are not provided in the snippet.\\n\\nOverall, the paper seems to be exploring the capabilities and limitations of text-to-image generators in supporting multiple languages, which is an important aspect of natural language processing and machine learning research.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.invoke({\"input\":\"What do u think these 2 articles\"})['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
